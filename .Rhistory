# Charger les librairies tidyverse et dplyr
# CreÌer un nouveau dataset en meÌlangant les lignes
#load dataset
data<-read.csv("data.csv",stringsAsFactors = TRUE)
wbcd<-data%>%sample_n(569)
table(wbcd$diagnosis)
# Enlever la colonne id qui ne sert aÌ rien pour la preÌdiction
wbcd<-wbcd[-1]
# Regarder la proportion de diagnostics M et B
table(wbcd$diagnosis)
#Transformer cette colonne diagnostic en facteur et donner un
#label clair aux codes B et M
wbcd$diagnosis<-factor(wbcd$diagnosis,levels = c("B","M"),labels = c("Benin","Malin"))
View(wbcd)
#On examine les trois dernieres variables
summary(wbcd[c("radius_mean","area_mean","smoothness_mean")])
# on constate une grande dispariteÌ dans l'amplitude des 3 variables area_mean varie
# entre 143 et 2501 pendant que smoothness_mean varie entre 0,05 et 0,16
# area_mean risque de fausser le resultat de la prediction il faut donc equilibrer
# l'amplitude de chaque variable pour cela on creÌe une fonction normalise
normalize <- function(x) {return ((x - min(x)) / ((max(x) - min(x))))}
View(normalize)
#la commande lapply applique la fonction normalize sur les colonnes 2 aÌ 31 du dataset
# Cette commande agit sur une liste or un data frame est un ensemble de liste il faut
# donc transformer le dataset en dataframe
wbcd_n <- as.data.frame(lapply(wbcd[,2:31], normalize))
View(wbcd_n)
summary(wbcd_n[c("radius_mean","area_mean","smoothness_mean")])
# CreÌation de deux dataset train et test
wbcdtrain<-wbcd_n[1:469,]
wbcdtest<-wbcd_n[470:569,]
install.packages("class")
library(class)
# on reÌalise la prediction avec la syntaxe p<-knn(train,test,cl,k)
# train et test sont les dataframe correspondants cl est le vecteur avec la classe de chaque
# ligne du dataframe train k est le nombre de plus proches voisins aÌ inclure dans le vote
wbcd_pred<-knn(train = wbcdtrain, test = wbcdtest, cl=wbcd_train_labels$diagnosis, k=21)
#Pour l'entrainement du modeÌle il faut stocker les labels Malin Benin de la premiere colonne
# du dataset initial
wbcd_train_labels<-wbcd[1:469,1]
wbcd_test_labels<-wbcd[470:569,1]
# on reÌalise la prediction avec la syntaxe p<-knn(train,test,cl,k)
# train et test sont les dataframe correspondants cl est le vecteur avec la classe de chaque
# ligne du dataframe train k est le nombre de plus proches voisins aÌ inclure dans le vote
wbcd_pred<-knn(train = wbcdtrain, test = wbcdtest, cl=wbcd_train_labels$diagnosis, k=21)
# on reÌalise la prediction avec la syntaxe p<-knn(train,test,cl,k)
# train et test sont les dataframe correspondants cl est le vecteur avec la classe de chaque
# ligne du dataframe train k est le nombre de plus proches voisins aÌ inclure dans le vote
wbcd_pred<-knn(train = wbcdtrain, test = wbcdtest, cl=wbcd_train_labels, k=21)
install.packages("gmodels")
library(gmodels)
CrossTable(x=wbcd_test_labels,y=wbcd_pred,prop.chisq=FALSE)
ggplot2::diamonds
d1<- ggplot2::diamonds
View(d1)
str(d1)
summary(d1$price)
hist(d1$price)
ggplot(data=d1,mapping = aes(price,carat))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,depth))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,table))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,x))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,y))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,z))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping= aes(cut,price))+geom_bar(aes(fill=clarity))
ggplot(data=d1,mapping= aes(cut,price))+geom_bar()
ggplot(data=d1,mapping= aes(cut,price))+geom_boxplot()
ggplot(data=d1,mapping= aes(cut,price))+geom_barplot(stat="identity")
ggplot(data=d1,mapping= aes(cut,price))+geom_bar(stat="identity")
ggplot(data=d1,mapping= aes(cut,price,fill=clarity))+geom_bar(stat="identity")
ggplot(data=d1,mapping= aes(color,price))+geom_boxplot()
ggplot(data=d1,mapping= aes(color,price,fill=clarity))+geom_bar(stat="identity")
ggplot(data=d1,mapping= aes(clarity,price))+geom_boxplot()
ggplot(data=d1,mapping= aes(color,price,fill=cut))+geom_bar(stat="identity")
ggplot(data=d1,mapping= aes(clarity,price,fill=cut))+geom_bar(stat="identity")
cor(d1[c(carat,depth,x,y,z,price)])
cor(d1[c("carat","depth","x","y","z","price")])
detach("package:psych", unload = TRUE)
library(psych)
pairs.panels(d1[c("carat","depth","x","y","z","price")])
price_model<- lm(price~ .,d1)
summary(price_model)
d1_train<- d1[1:42790]
d1_train<- d1[1:42790,]
d1_test<- d1[42791:53490,]
price_modelq <- lm(price~carat+depth+x+y+z,d1)
summary(price_modelq)
price_modelq <- lm(price~carat+depth+x+y+z,d1_train)
summary(price_modelq)
pred1<- predict(price_modelq,d1_test)
cor(pred1,d1_test$price)
price_modelb<lm(price~ .,d1_train)
price_modelb<-lm(price~ .,d1_train)
summary(price_modelb)
predf<- predict(price_modelb,d1_test)
cor(predf,d1_test)
cor(predf,d1_test$price)
head(pred1)
head(predf)
head(d1$test)
head(d1_test$price)
comparison1<- cbind(d1_test$price,pred1)
View(comparison1)
comparison2<- cbind(d1_test$price,predf)
price_modelq
price_modelb
table(d1$cut)
ggplot(data=d1,mapping=aes(cut,clarity))+geom_jitter()
ggplot(data=d1,mapping=aes(cut,color))+geom_jitter()
ggplot(data=d1,mapping=aes(cut,color,color="blue"))+geom_jitter()
ggplot(data=d1,mapping=aes(cut,clarity,color="red"))+geom_jitter()
ggplot(data=d1,mapping=aes(cut,color,color=color))+geom_jitter()
ggplot(data=d1,mapping=aes(cut,clarity,color=clarity))+geom_jitter()
ggplot(data=d1,mapping=aes(carat,cut,color=carat))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,carat,color=carat))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,depth,color=carat))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,depth,color=depth))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,depth,color=depth))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,x,color=x))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,y,color=carat))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,y,color=y))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,z,color=z))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(x=cut,color=price))+geom_bar()
ggplot(data=d1,mapping=aes(x=cut,color="green"))+geom_bar()
ggplot(data=d1,mapping=aes(x=cut,color="red"))+geom_bar()
ggplot(data=d1,mapping=aes(x=cut))+geom_bar()
ggplot(data=d1,mapping=aes(cut,price,color=price))+geom_bar(stat="identity")
normalize <- function(x) {return ((x - min(x)) / ((max(x) - min(x))))}
ggplot(data=d1,mapping=aes(cut,table,color=table))+geom_bar(stat="identity")
summary(d1$carat,d1$depth,d1$table,d1$price,d1$x,d1$y,d1$z)
summary(c(d1$carat,d1$depth,d1$table,d1$price,d1$x,d1$y,d1$z))
summary(d1[c(d1$carat,d1$depth,d1$table,d1$price,d1$x,d1$y,d1$z)])
summary(d1[c("carat","depth","table","price","x","y","z")])
d1f< d1[-2]
d1f<- d1[-2]
View(d1f)
d1f_n <-  as.data.frame(lapply(d1f, normalize))
d1f_n <-  as.data.frame(lapply(d1f$carat,d1$depth, normalize))
d1f_n <-  as.data.frame(lapply(d1f[c("carat","depth","table","price","x","y","z")], normalize))
View(d1f_n)
d1f_train<- d1f[1:42790,]
d1f_test<- d1f[42791:53940,]
d1label_train<- d1[1:42790,1]
d1label_test<- d1[42791:53940,1]
View(d1label_train)
View(d1label_test)
d1label_train<- d1[1:42790,2]
d1label_test<- d1[42791:53940,2]
detach("package:class", unload = TRUE)
library(class)
d1f_n$cut<- d1$cut
d1fn_train<- d1f_n[1:42790,]
d1fn_test<- d1f_n[42791:53940,]
View(d1fn_train)
View(d1label_train)
wbcd_pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=5)
wbcd_pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1fn_train$cut, k=5)
View(d1fn_train)
#Aller sur Kaggle puis rechercher Wisconsin Breast Cancer dataset et faire download
# le dataset s'appelle data.csv le renommer en wisc_bc_data.csv
# Charger les librairies tidyverse et dplyr
# CreÌer un nouveau dataset en meÌlangant les lignes
#load dataset
data<-read.csv("data.csv",stringsAsFactors = TRUE)
wbcd<-data%>%sample_n(569)
# Enlever la colonne id qui ne sert aÌ rien pour la preÌdiction
wbcd<-wbcd[-1]
View(wbcd)
View(d1f_train)
View(d1f_n)
d1f<- d1[-2]
d1f_n <-  as.data.frame(lapply(d1f[c("carat","depth","table","price","x","y","z")], normalize))
d1f_n$cut<- d1$cut
d1fn_train<- d1f_n[1:42790,]
d1fn_test<- d1f_n[42791:53940,]
d1label_train<- d1[1:42790,2]
d1label_test<- d1[42791:53940,2]
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=5)
d1label_train<- d1fn_train[8]
d1label_test<- d1fn_test[8]
View(d1label_train)
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=5)
d1<- ggplot2::diamonds
str(d1)
summary(d1$price)
hist(d1$price)
ggplot(data=d1,mapping = aes(price,carat))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,depth))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,table))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,x))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,y))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping = aes(price,z))+geom_point(aes(color=cut))+geom_smooth()
ggplot(data=d1,mapping= aes(cut,price))+geom_boxplot()
ggplot(data=d1,mapping= aes(cut,price,fill=clarity))+geom_bar(stat="identity")
ggplot(data=d1,mapping= aes(color,price))+geom_boxplot()
ggplot(data=d1,mapping= aes(color,price,fill=clarity))+geom_bar(stat="identity")
ggplot(data=d1,mapping= aes(clarity,price))+geom_boxplot()
ggplot(data=d1,mapping= aes(clarity,price,fill=cut))+geom_bar(stat="identity")
cor(d1[c("carat","depth","x","y","z","price")])
pairs.panels(d1[c("carat","depth","x","y","z","price")])
price_model<- lm(price~ .,d1)
summary(price_model)
d1_train<- d1[1:42790,]
d1_test<- d1[42791:53490,]
price_modelq <- lm(price~carat+depth+x+y+z,d1_train)
summary(price_modelq)
pred1<- predict(price_modelq,d1_test)
cor(pred1,d1_test$price)
price_modelb<-lm(price~ .,d1_train)
summary(price_modelb)
predf<- predict(price_modelb,d1_test)
cor(predf,d1_test$price)
head(pred1)
head(predf)
head(d1_test$price)
head(pred1)
head(predf)
head(d1_test$price)
comparison1<- cbind(d1_test$price,pred1)
comparison2<- cbind(d1_test$price,predf)
price_modelq
price_modelb
table(d1$cut)
ggplot(data=d1,mapping=aes(x=cut))+geom_bar()
ggplot(data=d1,mapping=aes(cut,clarity,color=clarity))+geom_jitter()
ggplot(data=d1,mapping=aes(cut,color,color=color))+geom_jitter()
ggplot(data=d1,mapping=aes(cut,carat,color=carat))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,depth,color=depth))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,x,color=x))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,y,color=y))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,z,color=z))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,price,color=price))+geom_bar(stat="identity")
ggplot(data=d1,mapping=aes(cut,table,color=table))+geom_bar(stat="identity")
normalize <- function(x) {return ((x - min(x)) / ((max(x) - min(x))))}
summary(d1[c("carat","depth","table","price","x","y","z")])
d1f<- d1[-2]
View(d1f)
d1f_n <-  as.data.frame(lapply(d1f[c("carat","depth","table","price","x","y","z")], normalize))
d1f_n$cut<- d1$cut
d1fn_train<- d1f_n[1:42790,]
d1fn_test<- d1f_n[42791:53940,]
d1label_train<- d1fn_train[8]
d1label_test<- d1fn_test[8]
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=5)
pred<-knn(train = d1fn_train[,1:7], test = d1fn_test, cl=d1label_train, k=5)
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=5)
detach("package:class", unload = TRUE)
library(class)
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=5)
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=21)
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train, k=10)
View(d1fn_train)
View(d1label_train)
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1fn_train[,8], k=10)
d1label_train<- d1fn_train[,8]
d1label_test<- d1fn_test[8]
d1label_train<- d1fn_train[8]
View(d1label_train)
dim(d1label_train)
dim(d1fn_train)
len(d1fn_train)
pred<-knn(train = d1fn_train, test = d1fn_test, cl=d1label_train[,1], k=10)
cl1= d1label_train[,1]
cl1
pred<-knn(train = d1fn_train, test = d1fn_test, cl=cl1, k=10)
length(d1label_train)
length(d1fn_train)
length(cl1)
fr_train<- as.data.frame(d1fn_train)
fr_test<- as.data.frame(d1fn_test)
frlab<- as.data.frame(d1label_train)
pred<-knn(train = fr_train, test = fr_test, cl=frlab, k=10)
cl1= d1label_train[,1,drop=TRUE]
pred<-knn(train = fr_train, test = fr_test, cl=cl1, k=10)
cl1= d1label_train[,1,drop=FALSE]
pred<-knn(train = fr_train, test = fr_test, cl=cl1, k=10)
pred<-knn(train = fr_train[drop=FALSE], test = fr_test, cl=cl1, k=10)
d1f<- d1[-2,drop=FALSE]
d1f<- d1[-2]
d1f_n <-  as.data.frame(lapply(d1f[c("carat","depth","table","price","x","y","z")], normalize))
d1f_n$cut<- d1$cut
d1fn_train<- d1f_n[1:42790,]
d1fn_test<- d1f_n[42791:53940,]
d1label_train<- d1fn_train[8]
d1label_test<- d1fn_test[8]
dim(d1label_train)
dim(d1fn_train)
fr_train<- as.data.frame(d1fn_train)
fr_test<- as.data.frame(d1fn_test)
frlab<- as.data.frame(d1label_train)
cl1= d1label_train[,1,drop=FALSE]
pred<-knn(train = fr_train, test = fr_test, cl=cl1, k=10)
length(d1fn_train)
length(cl1)
pred<-knn(train = fr_train, test = fr_test, cl=d1label_train$cut, k=10)
View(d1fn_train)
d1label_train<- d1f_n[1:42970,8]
d1label_test<- d1fn_test[42791:53940,8]
pred<-knn(train = fr_train, test = fr_test, cl=d1label_train$cut, k=10)
pred<-knn(train = fr_train, test = fr_test, cl=d1label_train, k=10)
pred<-knn(train = fr_train, test = fr_test, cl=d1label_train, k=10)
pred<-knn(train = fr_train, test = fr_test, cl=frlab, k=10)
pred<-knn(train = fr_train, test = fr_test, cl=cl1, k=10)
View(cl1)
str(d1)
str(d1fn_train)
str(d1label_train)
install.packages("caret")
library(caret)
trcontrol<- trainControl(method ="repeatedcv",number = 10,repeats=3)
View(trcontrol)
fit<- train(cut~ ., data = d1fn_train, method= 'knn', trcontrol=trcontrol)
fit<- train(cut~ ., data = d1fn_train, method= 'knn')
View(d1f)
View(d1f)
View(d1f)
View(d1f)
d1fq<- d1f[c("carat","depth","table","price","x","y","z")]
d1fq<- d1[c("carat","depth","table","price","x","y","z","cut")]
View(d1fq)
set.seed(1234)
ind<- sample(2,nrow(d1fq),replace =T, prob=c(0.8,0.2))
training<- d1fq[ind==1,]
testing<- d1fq[ind==2,]
fit<- train(cut~ ., data = training, method= 'knn',tuneLength=20, trControl=trcontrol, preProc= c("center","scale"))
fit<- train(cut~ ., data = training, method= 'knn',tuneLength=20, trControl=trcontrol, preProc= c("center","scale"))
fit<- train(cut~ ., data = training, method= 'knn', trControl=trcontrol, preProc= c("center","scale"))
fit
plot(fit)
varImp(fit)
predict(fit, newdata = testing)
predknn <-predict(fit, newdata = testing)
confusionMatrix(predknn,testing$cut)
plot(price_modelb)
getwd()
setwd(dir = "C:/Users/User/Documents/Predictive analyitics")
getwd()
df <- read.csv("HR-Attrition.csv")
summary(df)
names<- c("Education","Attrition","EnvironmentSatisfaction","JobInvolvement","JobLevel","JobSatisfaction","NumCompaniesWorked","PerformanceRating",
"RelationshipSatisfaction","StockOptionLevel","TrainingTimesLastYear","WorkLifeBalance")
df[,names]<- lapply(df[,names],factor)
summary(df)
dfn<- select(df,-c("StandardHours","Over18","EmployeeNumber","EmployeeCount"))
dffeatures<- select(dfn,-c("Attrition"))
library(dplyr)
install.packages("tidyverse")
library(tidyverse)
library(caret)
library(randomForest)
library(adabag)
library(xgboost)
library(psych)
getwd()
setwd(dir = "C:/Users/User/Documents/Predictive analyitics")
getwd()
df <- read.csv("HR-Attrition.csv")
summary(df)
names<- c("Education","Attrition","EnvironmentSatisfaction","JobInvolvement","JobLevel","JobSatisfaction","NumCompaniesWorked","PerformanceRating",
"RelationshipSatisfaction","StockOptionLevel","TrainingTimesLastYear","WorkLifeBalance")
df[,names]<- lapply(df[,names],factor)
summary(df)
dfn<- select(df,-c("StandardHours","Over18","EmployeeNumber","EmployeeCount"))
dffeatures<- select(dfn,-c("Attrition"))
#Train-test split
set.seed(1234)
ind<- sample(2, nrow(dfn), replace=TRUE, prob=c(0.8,0.2))
training <- dfn[ind==1,]
testing <- dfn[ind==2,]
y_train <- training[,2]
x_train <- training[,-2]
x_test <- testing[,-2]
y_test<- testing[,2]
#control<- trainControl(method='repeatedcv', number=10, repeats= 3, search='random')
set.seed(1)
bestmtry <- tuneRF(x_train, y_train,stepFactor = 1.5,improve = 1e-5,ntree=500)
modelrf <- randomForest(x_train,y_train,ntree = 500, mtry = 4, importance = TRUE)
modelrf
pred= predict(modelrf,training)
pred1= predict(modelrf,testing)
confusionMatrix(testing$Attrition,pred1)
importancerf <-round(importance(modelrf),2)
newimp <-data.frame(importancerf)
plot(newimp$MeanDecreaseAccuracy)
postResample(pred,training$Attrition)
postResample(pred1,testing$Attrition)
plot(modelrf)
#Random Forest with Grid Search
control <- trainControl(method='repeatedcv',number=10, repeats=3,search='grid')
tunegrid <- expand.grid(.mtry=(1:15))
rf_grid <- train(Attrition ~.,data = training,method='rf',metric='Accuracy',tuneGrid=tunegrid)
print(rf_grid)
plot(rf_grid)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(randomForest)
library(adabag)
library(xgboost)
library(psych)
plot(pressure)
install.packages("ROCR")
library(ROCR)
getwd()
setwd(dir = "C:/Users/User/Documents/Predictive analyitics")
getwd()
df <- read.csv("HR-Attrition.csv")
summary(df)
names<- c("Education","Attrition","EnvironmentSatisfaction","JobInvolvement","JobLevel","JobSatisfaction","NumCompaniesWorked","PerformanceRating",
"RelationshipSatisfaction","StockOptionLevel","TrainingTimesLastYear","WorkLifeBalance")
df[,names]<- lapply(df[,names],factor)
summary(df)
dfn<- select(df,-c("StandardHours","Over18","EmployeeNumber","EmployeeCount"))
#Train-test split
set.seed(1234)
ind<- sample(2, nrow(dfn), replace=TRUE, prob=c(0.8,0.2))
training <- dfn[ind==1,]
testing <- dfn[ind==2,]
y_train <- training[,2]
x_train <- training[,-2]
x_test <- testing[,-2]
#control<- trainControl(method='repeatedcv', number=10, repeats= 3, search='random')
set.seed(1)
bestmtry <- tuneRF(x_train, y_train,stepFactor = 1.5,improve = 1e-5,ntree=500)
modelrf <- randomForest(x_train,y_train,ntree = 500, mtry = 4, importance = TRUE)
modelrf
pred= predict(modelrf,training)
pred1= predict(modelrf,testing)
confusionMatrix(testing$Attrition,pred1)
importancerf <-round(importance(modelrf),2)
newimp <-data.frame(importancerf)
plot(newimp$MeanDecreaseAccuracy)
plot(modelrf)
modellogr= glm(formula=Attrition ~.,data = training,family = binomial)
summary(modellogr)
anova(modellogr,test = "Chisq")
predlr= predict(modellogr, testing, type = "response")
binpred= ifelse(predlr>0.5,"Yes","No")
mean(binpred == testing$Attrition)
postResample(binpred,testing$Attrition)
plot(modellogr)
pr<- prediction(predlr, testing$Attrition)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
#Model-3: Gradient Boosted Tree (XG Boost)
controlxg <- trainControl(method='repeatedcv',number=10, repeats=3)
modelxgcv <- train(Attrition ~., data=training, method='xgbTree',trControl=controlxg)
plot(modelxgcv)
predxg <- predict(modelxg,testing)
#Model-3: Gradient Boosted Tree (XG Boost)
controlxg <- trainControl(method='repeatedcv',number=10, repeats=3)
modelxgcv <- train(Attrition ~., data=training, method='xgbTree',trControl=controlxg)
predxg <- predict(modelxg,testing)
mean(predxg==testing$Attrition)
postResample(predxg,testing$Attrition)
impxg <-varImp(modelxg)
plot(impxg)
predxg <- predict(modelxgcv,testing)
modelxgcv <- train(Attrition ~., data=training, method='xgbTree',trControl=controlxg)
predxg <- predict(modelxgcv,testing)
mean(predxg==testing$Attrition)
postResample(predxg,testing$Attrition)
impxg <-varImp(modelxg)
plot(impxg)
predxg <- predict(modelxgcv,testing)
#Model-3: Gradient Boosted Tree (XG Boost)
controlxg <- trainControl(method='repeatedcv',number=10, repeats=3)
modelxgcv <- train(Attrition ~., data=training, method='xgbTree',trControl=controlxg)
#Model-3: Gradient Boosted Tree (XG Boost)
controlxg <- trainControl(method='repeatedcv',number=10, repeats=3)
modelxgcv <- train(Attrition ~., data=training, method='xgbTree',trControl=controlxg)
getwd()
setwd(dir = "C:/Users/User/Documents/Predictive analyitics")
getwd()
df <- read.csv("HR-Attrition.csv")
summary(df)
names<- c("Education","Attrition","EnvironmentSatisfaction","JobInvolvement","JobLevel","JobSatisfaction","NumCompaniesWorked","PerformanceRating",
"RelationshipSatisfaction","StockOptionLevel","TrainingTimesLastYear","WorkLifeBalance")
df[,names]<- lapply(df[,names],factor)
summary(df)
dfn<- select(df,-c("StandardHours","Over18","EmployeeNumber","EmployeeCount"))
#Train-test split
set.seed(1234)
ind<- sample(2, nrow(dfn), replace=TRUE, prob=c(0.8,0.2))
training <- dfn[ind==1,]
testing <- dfn[ind==2,]
y_train <- training[,2]
x_train <- training[,-2]
x_test <- testing[,-2]
y_test<- testing[,2]
#control<- trainControl(method='repeatedcv', number=10, repeats= 3, search='random')
set.seed(1)
bestmtry <- tuneRF(x_train, y_train,stepFactor = 1.5,improve = 1e-5,ntree=500)
modelrf <- randomForest(x_train,y_train,ntree = 500, mtry = 4, importance = TRUE)
modelrf
pred= predict(modelrf,training)
pred1= predict(modelrf,testing)
confusionMatrix(testing$Attrition,pred1)
importancerf <-round(importance(modelrf),2)
newimp <-data.frame(importancerf)
plot(newimp$MeanDecreaseAccuracy)
postResample(pred,training$Attrition)
postResample(pred1,testing$Attrition)
plot(modelrf)
#Random Forest with Grid Search
control <- trainControl(method='repeatedcv',number=10, repeats=3,search='grid')
tunegrid <- expand.grid(.mtry=(1:15))
rf_grid <- train(Attrition ~.,data = training,method='rf',metric='Accuracy',tuneGrid=tunegrid)
print(rf_grid)
